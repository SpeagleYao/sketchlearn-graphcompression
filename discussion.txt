method 1: 
show line plots of test6
why k should be larger

original storage: n (type of edges) (400/2000) * k （320） bits
storage of method 1: row * c * k (320) * (sizeof(int))



thre = total_frequence/c

compute column number by portion of frequence we want to extract:
portion of frequence: p=0.5
step 1: sort all frequences  e.g. [1, 1, 1, 3], [1,1,2,2]
step 2: adding from the largest until reach the portion p 
step 3: set the stop point as the threshold, thre=3-1=2 
step 4: compute c = total_frequence/threshold

storage: r * total_frequence/threshold * sizeof(int)



method 2: not effective (still need to infer the whole sketch table). After adding another sketch table, precision stays 1, recall does not change too much
to improve: build sketch table of the 160 LSBs for each stack in the sketch table of 160 MSBs

edge: RID1+RID2 100
in higher level sketch table S, feed RID1 to stack r, c
in S[r][c]'s sketch table, feed RID2

storage: r*c* k/2 + r*c*r'*c'* k/2  =====>  r1 * c1 * r2 * (total_frequence/c1)/threshold * sizeof(int)

RID1+RID3 100

100<thre

thre = n/c

RID1 200

r'*c'*k/2 : 2 100 flow  r', c' << r, c




method 3: similar to method 1


a sketch

ProbLog: Scale probability to frequency
p(RID1) = p(EDB1) * p(EDB2) * ... * ruleweight   P(IDB) = CNF(EDB, rule weight)
save p to the sketch, then scale the table

r1 know(1,2) :- know(1,3),know(3,2) IDB
prov(know(1,2), r1)
ruleexcu(r1, know(1,3), know(3,2))

packet forward: 
edge(know(1,2), hash(r1))
edge(r1, know(1,3))
edge(r1, know(3,2))



use sketch for monte carlo simulation
given set of probabilistic tuples: packet(@1,1,3,data): 0.8, route(@1,3,2): 0.5
for n rounds:
    insert each probabilistic tuple with its probability
    insert edges of RIDs if the rules are triggered:  
        r1 0.4 packet(@2,1,3,data) :- packet(@1,1,3,data), route(@1,3,2)   <====> r3 packet(@1,1,3,data) :-    r1-r3 
        r2 0.5 packet(@2,1,3,data) :- packet(@4,1,3,data), route(@4,3,2) 
    clear all tuples


R1-r2 50 100
r1-r3 10
r1-r4 10
r1-r5 10
r1-r6 10